{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-fake-news.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwX3y-782I_T",
        "colab_type": "code",
        "outputId": "4a584fd2-e049-45c4-92a1-9f143de084a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdS-5P5G2QWS",
        "colab_type": "code",
        "outputId": "b5f45654-6e99-4a40-a7e1-8578f6f10b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!python3 -m pip install --user bert-tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 27.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 31.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 35.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 39.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 42.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTlg3zM2MGB",
        "colab_type": "code",
        "outputId": "246f8128-a153-45ce-dca9-ccc51acf6ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import glob\n",
        "import pathlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.datasets import load_files\n",
        "from tqdm import tqdm\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__))\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 10898407511658723436, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 18344317799076504172\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 18050405717902452905\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14892338381\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 10752917613540893293\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x8-sSQ73PyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5223f2c7-4116-45ca-a512-a1423e5a1ad9"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/bert/')\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD1ggX6z2I_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier, optimization, tokenization, modeling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaO0xyMxAnC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3a684d3b-8d83-403f-9bf1-32d3f23d8c00"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip -O ./uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-08 05:16:39--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.197.176, 2404:6800:4004:80f::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.197.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘./uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "./uncased_L-12_H-76 100%[===================>] 388.84M  61.0MB/s    in 6.1s    \n",
            "\n",
            "2019-07-08 05:16:45 (63.7 MB/s) - ‘./uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDaYOnmUAsOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8f68314d-4246-46eb-a593-75f8648949c3"
      },
      "source": [
        "!unzip ./uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lQ38vvrA4zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3d5e2e92-fe3d-4303-d07d-cfdd58f3c80c"
      },
      "source": [
        "!ls ./uncased_L-12_H-768_A-12/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n",
            "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76G-PzV0gHzD",
        "colab_type": "code",
        "outputId": "b697a242-b9fe-436d-ea0b-3f2c1e604cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip -O ./model/wwm_uncased_L-24_H-1024_A-16.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['--2019-07-06 13:40:15--  https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip',\n",
              " 'Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c01::80',\n",
              " 'Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.',\n",
              " 'HTTP request sent, awaiting response... 200 OK',\n",
              " 'Length: 1248381879 (1.2G) [application/zip]',\n",
              " 'Saving to: ‘./model/wwm_uncased_L-24_H-1024_A-16.zip’',\n",
              " '',\n",
              " '',\n",
              " '          ./model/w   0%[                    ]       0  --.-KB/s               ',\n",
              " '         ./model/ww   0%[                    ]   9.52M  47.4MB/s               ',\n",
              " '        ./model/wwm   1%[                    ]  23.66M  59.1MB/s               ',\n",
              " '       ./model/wwm_   3%[                    ]  38.29M  63.7MB/s               ',\n",
              " '      ./model/wwm_u   4%[                    ]  51.84M  64.8MB/s               ',\n",
              " '     ./model/wwm_un   5%[>                   ]  66.59M  66.5MB/s               ',\n",
              " '    ./model/wwm_unc   6%[>                   ]  81.47M  67.8MB/s               ',\n",
              " '   ./model/wwm_unca   8%[>                   ]  96.38M  68.8MB/s               ',\n",
              " '  ./model/wwm_uncas   9%[>                   ] 111.51M  69.7MB/s               ',\n",
              " ' ./model/wwm_uncase  10%[=>                  ] 123.52M  68.6MB/s               ',\n",
              " './model/wwm_uncased  11%[=>                  ] 137.05M  68.5MB/s               ',\n",
              " '/model/wwm_uncased_  12%[=>                  ] 149.79M  68.1MB/s               ',\n",
              " 'model/wwm_uncased_L  13%[=>                  ] 162.66M  67.7MB/s               ',\n",
              " 'odel/wwm_uncased_L-  14%[=>                  ] 175.02M  67.3MB/s               ',\n",
              " 'del/wwm_uncased_L-2  15%[==>                 ] 188.49M  67.3MB/s               ',\n",
              " 'el/wwm_uncased_L-24  17%[==>                 ] 203.79M  67.9MB/s    eta 15s    ',\n",
              " 'l/wwm_uncased_L-24_  18%[==>                 ] 218.87M  69.8MB/s    eta 15s    ',\n",
              " '/wwm_uncased_L-24_H  19%[==>                 ] 233.46M  69.9MB/s    eta 15s    ',\n",
              " 'wwm_uncased_L-24_H-  20%[===>                ] 248.84M  70.3MB/s    eta 15s    ',\n",
              " 'wm_uncased_L-24_H-1  22%[===>                ] 263.52M  70.6MB/s    eta 15s    ',\n",
              " 'm_uncased_L-24_H-10  23%[===>                ] 276.30M  70.0MB/s    eta 13s    ',\n",
              " '_uncased_L-24_H-102  24%[===>                ] 290.57M  70.1MB/s    eta 13s    ',\n",
              " 'uncased_L-24_H-1024  25%[====>               ] 304.85M  69.6MB/s    eta 13s    ',\n",
              " 'ncased_L-24_H-1024_  26%[====>               ] 318.55M  69.2MB/s    eta 13s    ',\n",
              " 'cased_L-24_H-1024_A  27%[====>               ] 332.02M  69.4MB/s    eta 13s    ',\n",
              " 'ased_L-24_H-1024_A-  29%[====>               ] 345.68M  69.3MB/s    eta 12s    ',\n",
              " 'sed_L-24_H-1024_A-1  30%[=====>              ] 360.76M  70.1MB/s    eta 12s    ',\n",
              " 'ed_L-24_H-1024_A-16  31%[=====>              ] 375.36M  70.7MB/s    eta 12s    ',\n",
              " 'd_L-24_H-1024_A-16.  32%[=====>              ] 390.09M  71.5MB/s    eta 12s    ',\n",
              " '_L-24_H-1024_A-16.z  33%[=====>              ] 402.91M  71.4MB/s    eta 12s    ',\n",
              " 'L-24_H-1024_A-16.zi  35%[======>             ] 416.73M  71.1MB/s    eta 11s    ',\n",
              " '-24_H-1024_A-16.zip  36%[======>             ] 430.38M  70.4MB/s    eta 11s    ',\n",
              " '24_H-1024_A-16.zip   37%[======>             ] 441.40M  69.5MB/s    eta 11s    ',\n",
              " '4_H-1024_A-16.zip    37%[======>             ] 452.38M  68.1MB/s    eta 11s    ',\n",
              " '_H-1024_A-16.zip     39%[======>             ] 465.08M  67.2MB/s    eta 11s    ',\n",
              " 'H-1024_A-16.zip      40%[=======>            ] 479.55M  67.9MB/s    eta 10s    ',\n",
              " '-1024_A-16.zip       41%[=======>            ] 493.30M  67.6MB/s    eta 10s    ',\n",
              " '1024_A-16.zip        42%[=======>            ] 502.05M  65.7MB/s    eta 10s    ',\n",
              " '024_A-16.zip         43%[=======>            ] 514.48M  65.3MB/s    eta 10s    ',\n",
              " '24_A-16.zip          44%[=======>            ] 528.02M  65.2MB/s    eta 10s    ',\n",
              " '4_A-16.zip           45%[========>           ] 542.41M  65.9MB/s    eta 10s    ',\n",
              " '_A-16.zip            46%[========>           ] 556.17M  65.4MB/s    eta 10s    ',\n",
              " 'A-16.zip             47%[========>           ] 567.95M  64.5MB/s    eta 10s    ',\n",
              " '-16.zip              48%[========>           ] 580.40M  63.6MB/s    eta 10s    ',\n",
              " '16.zip               49%[========>           ] 594.02M  63.7MB/s    eta 10s    ',\n",
              " '6.zip                51%[=========>          ] 609.27M  64.5MB/s    eta 9s     ',\n",
              " '.zip                 52%[=========>          ] 624.85M  65.0MB/s    eta 9s     ',\n",
              " 'zip                  53%[=========>          ] 639.76M  65.5MB/s    eta 9s     ',\n",
              " 'ip                   55%[==========>         ] 655.31M  67.0MB/s    eta 9s     ',\n",
              " 'p                    56%[==========>         ] 669.73M  68.2MB/s    eta 9s     ',\n",
              " '                     57%[==========>         ] 681.44M  67.5MB/s    eta 7s     ',\n",
              " '                  .  58%[==========>         ] 696.96M  68.2MB/s    eta 7s     ',\n",
              " '                 ./  59%[==========>         ] 711.41M  69.4MB/s    eta 7s     ',\n",
              " '                ./m  60%[===========>        ] 725.02M  70.4MB/s    eta 7s     ',\n",
              " '               ./mo  61%[===========>        ] 736.38M  69.2MB/s    eta 7s     ',\n",
              " '              ./mod  63%[===========>        ] 750.22M  69.4MB/s    eta 6s     ',\n",
              " '             ./mode  64%[===========>        ] 763.52M  69.0MB/s    eta 6s     ',\n",
              " '            ./model  64%[===========>        ] 773.75M  68.0MB/s    eta 6s     ',\n",
              " '           ./model/  66%[============>       ] 788.81M  69.3MB/s    eta 6s     ',\n",
              " '          ./model/w  67%[============>       ] 801.49M  69.1MB/s    eta 6s     ',\n",
              " '         ./model/ww  68%[============>       ] 815.52M  69.1MB/s    eta 6s     ',\n",
              " '        ./model/wwm  69%[============>       ] 830.02M  68.5MB/s    eta 6s     ',\n",
              " '       ./model/wwm_  70%[=============>      ] 842.02M  67.7MB/s    eta 6s     ',\n",
              " '      ./model/wwm_u  71%[=============>      ] 855.26M  67.2MB/s    eta 6s     ',\n",
              " '     ./model/wwm_un  72%[=============>      ] 866.25M  65.6MB/s    eta 6s     ',\n",
              " '    ./model/wwm_unc  73%[=============>      ] 880.02M  66.1MB/s    eta 5s     ',\n",
              " '   ./model/wwm_unca  74%[=============>      ] 891.66M  65.6MB/s    eta 5s     ',\n",
              " '  ./model/wwm_uncas  75%[==============>     ] 904.55M  64.4MB/s    eta 5s     ',\n",
              " ' ./model/wwm_uncase  77%[==============>     ] 918.08M  64.5MB/s    eta 5s     ',\n",
              " './model/wwm_uncased  78%[==============>     ] 930.52M  64.2MB/s    eta 5s     ',\n",
              " '/model/wwm_uncased_  79%[==============>     ] 944.54M  64.8MB/s    eta 4s     ',\n",
              " 'model/wwm_uncased_L  80%[===============>    ] 957.69M  64.6MB/s    eta 4s     ',\n",
              " 'odel/wwm_uncased_L-  81%[===============>    ] 971.77M  65.5MB/s    eta 4s     ',\n",
              " 'del/wwm_uncased_L-2  82%[===============>    ] 984.45M  65.4MB/s    eta 4s     ',\n",
              " 'el/wwm_uncased_L-24  83%[===============>    ] 993.84M  64.2MB/s    eta 4s     ',\n",
              " 'l/wwm_uncased_L-24_  84%[===============>    ]   1003M  62.8MB/s    eta 3s     ',\n",
              " '/wwm_uncased_L-24_H  85%[================>   ]   1017M  62.3MB/s    eta 3s     ',\n",
              " 'wwm_uncased_L-24_H-  86%[================>   ]   1.01G  63.5MB/s    eta 3s     ',\n",
              " 'wm_uncased_L-24_H-1  87%[================>   ]   1.02G  64.3MB/s    eta 3s     ',\n",
              " 'm_uncased_L-24_H-10  89%[================>   ]   1.04G  65.5MB/s    eta 3s     ',\n",
              " '_uncased_L-24_H-102  90%[=================>  ]   1.05G  66.3MB/s    eta 2s     ',\n",
              " 'uncased_L-24_H-1024  91%[=================>  ]   1.07G  66.0MB/s    eta 2s     ',\n",
              " 'ncased_L-24_H-1024_  92%[=================>  ]   1.08G  66.6MB/s    eta 2s     ',\n",
              " 'cased_L-24_H-1024_A  93%[=================>  ]   1.09G  66.8MB/s    eta 2s     ',\n",
              " 'ased_L-24_H-1024_A-  95%[==================> ]   1.11G  67.6MB/s    eta 2s     ',\n",
              " 'sed_L-24_H-1024_A-1  96%[==================> ]   1.12G  67.1MB/s    eta 1s     ',\n",
              " 'ed_L-24_H-1024_A-16  97%[==================> ]   1.13G  66.6MB/s    eta 1s     ',\n",
              " 'd_L-24_H-1024_A-16.  98%[==================> ]   1.14G  66.4MB/s    eta 1s     ',\n",
              " '_L-24_H-1024_A-16.z  99%[==================> ]   1.16G  66.2MB/s    eta 1s     ',\n",
              " './model/wwm_uncased 100%[===================>]   1.16G  66.2MB/s    in 18s     ',\n",
              " '',\n",
              " '2019-07-06 13:40:33 (67.2 MB/s) - ‘./model/wwm_uncased_L-24_H-1024_A-16.zip’ saved [1248381879/1248381879]',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG04H5-tgiG8",
        "colab_type": "code",
        "outputId": "70f6b89d-1390-40a1-8229-d0c53bf23ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip ./model/wwm_uncased_L-24_H-1024_A-16.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./model/wwm_uncased_L-24_H-1024_A-16.zip\n",
            "   creating: wwm_uncased_L-24_H-1024_A-16/\n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.meta  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/vocab.txt  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.index  \n",
            "  inflating: wwm_uncased_L-24_H-1024_A-16/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIfZOu8shFs5",
        "colab_type": "code",
        "outputId": "b75e1383-ee68-4b9b-9285-6843d89ba3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls ./wwm_uncased_L-24_H-1024_A-16/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n",
            "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNlutsr52I_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BERT_VOCAB= './uncased_L-12_H-768_A-12/vocab.txt'\n",
        "BERT_INIT_CHKPNT = './uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
        "BERT_CONFIG = './uncased_L-12_H-768_A-12/bert_config.json'\n",
        "OUTPUT_DIR = './output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXnZckxK2JAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenization.validate_case_matches_checkpoint(True, BERT_INIT_CHKPNT)\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=BERT_VOCAB, do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBihroAW2JAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = './data/train.csv'\n",
        "data = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# label 1 for unreliable, label 0 for reliable\n",
        "TEXT_COL = 'text'\n",
        "LABEL_COL = 'label'\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aYh_rshFQeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ae2e6f22-56f4-4e6c-d9f4-737f55915c8f"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11308</th>\n",
              "      <td>11308</td>\n",
              "      <td>Good Samaritan wearing Indian headdress disarm...</td>\n",
              "      <td>-NO AUTHOR-</td>\n",
              "      <td>Good Samaritan wearing Indian headdress disarm...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7991</th>\n",
              "      <td>7991</td>\n",
              "      <td>Hillary Clinton, Donald Trump, Vladimir Putin:...</td>\n",
              "      <td>Andrea Kannapell and Sandra Stevenson</td>\n",
              "      <td>(Want to get this briefing by email? Here’s th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>3962</td>\n",
              "      <td>Watch Ozzy Man’s incredibly sweary review of t...</td>\n",
              "      <td>OK</td>\n",
              "      <td>Next Swipe left/right Watch Ozzy Man’s incredi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16766</th>\n",
              "      <td>16766</td>\n",
              "      <td>NASA Actually Recorded Sound In Space. What Yo...</td>\n",
              "      <td>Dikran Arakelian (noreply@blogger.com)</td>\n",
              "      <td>Share on Facebook NASA Space Sounds: what happ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11461</th>\n",
              "      <td>11461</td>\n",
              "      <td>Norwegian Government to Deport White Patriot W...</td>\n",
              "      <td>Red Ice</td>\n",
              "      <td>Norwegian Government to Deport White Patriot W...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... label\n",
              "11308  11308  ...     1\n",
              "7991    7991  ...     0\n",
              "3962    3962  ...     1\n",
              "16766  16766  ...     1\n",
              "11461  11461  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJGhwgo2JAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_examples(df):\n",
        "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "    examples = []\n",
        "    for index, value in df.iterrows():\n",
        "        text_a = str(value['text'])\n",
        "        label = (value['label'])\n",
        "        examples.append(\n",
        "            bert.run_classifier.InputExample(guid=None, text_a=text_a,\n",
        "                                             text_b=None, label=label))\n",
        "    return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJLey7w02JAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_VAL_RATIO = 0.8\n",
        "LENGTH = train_data.shape[0]\n",
        "TRAIN_SIZE = int(TRAIN_VAL_RATIO*LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qu-Fn4M2JAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples = create_examples(train_data)\n",
        "test_examples = create_examples(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuknTjPn2JAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "label_list = [0, 1]\n",
        "\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_examples, \n",
        "                                                                  label_list,\n",
        "                                                                  MAX_SEQ_LENGTH, \n",
        "                                                                  tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_examples, \n",
        "                                                                  label_list,\n",
        "                                                                  MAX_SEQ_LENGTH, \n",
        "                                                                  tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlG2RM2XDyUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebc5326a-cfe0-4b12-a086-0e88f5662624"
      },
      "source": [
        "len(train_features), len(test_features)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16640, 4160)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXUWBinO2JAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 4\n",
        "\n",
        "WARMUP_PROPORTION = 0.1\n",
        "\n",
        "SAVE_CHECKPOINT_STEPS = 4000\n",
        "SAVE_SUMMARY_STEPS = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXKmj7_u2JAu",
        "colab_type": "code",
        "outputId": "223b5f36-67b0-465d-c5a8-f8079620bc7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "num_train_steps = int(len(train_features)/ BATCH_SIZE * EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num of training features = %d\" % len(train_features))\n",
        "print(\"  Batch size = %d\" % BATCH_SIZE)\n",
        "print(\"  Num steps = %d\"% num_train_steps)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num of training features = 16640\n",
            "  Batch size = 32\n",
            "  Num steps = 2080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXFDOjoL2JAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINT_STEPS\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3jYWbDdQckq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "677124d0-fc2d-4024-bf60-58993157952a"
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "bert_config.__dict__"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3R_Ze92JA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings=True):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "    model = modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "    output_layer = model.get_pooled_output()\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "    print('Hidden size: ',hidden_size)\n",
        "    \n",
        "    output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "    \n",
        "    with tf.variable_scope('loss'):\n",
        "        # fine-tuning last layer\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "        \n",
        "        # Convert labels into one-hot encoding\n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "        \n",
        "        predicted = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        \n",
        "        if is_training:\n",
        "            per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "            loss = tf.reduce_mean(per_example_loss)\n",
        "            return loss, predicted, log_probs\n",
        "            \n",
        "            \n",
        "        elif not is_training:\n",
        "            predicted = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "            return predicted, log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwdLzS9r2JA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(bert_config, init_checkpoint, num_labels, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "    # Wraps model_fn as Estimator\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        tf.logging.info(\"*** Features ***\")\n",
        "        for name in sorted(features.keys()):\n",
        "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "            \n",
        "        input_ids = features['input_ids']\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "        \n",
        "        is_training = (mode == tf.estimator.ModeKeys.TRAIN or \n",
        "                       mode == tf.estimator.ModeKeys.EVAL)\n",
        "            \n",
        "        # Training or evaluating\n",
        "        if is_training:\n",
        "            (total_loss, predicted_labels, log_probs) = create_model(bert_config, is_training,\n",
        "                                                              input_ids, input_mask,\n",
        "                                                              segment_ids, label_ids,\n",
        "                                                              num_labels)\n",
        "            # Calculate evaluation metrics. \n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                f1_score = tf.contrib.metrics.f1_score(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                auc = tf.metrics.auc(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                recall = tf.metrics.recall(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                precision = tf.metrics.precision(\n",
        "                    label_ids,\n",
        "                    predicted_labels) \n",
        "                true_pos = tf.metrics.true_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                true_neg = tf.metrics.true_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)   \n",
        "                false_pos = tf.metrics.false_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)  \n",
        "                false_neg = tf.metrics.false_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    \"f1_score\": f1_score,\n",
        "                    \"auc\": auc,\n",
        "                    \"precision\": precision,\n",
        "                    \"recall\": recall,\n",
        "                    \"true_positives\": true_pos,\n",
        "                    \"true_negatives\": true_neg,\n",
        "                    \"false_positives\": false_pos,\n",
        "                    \"false_negatives\": false_neg\n",
        "                }\n",
        "            \n",
        "            optimizer = bert.optimization.create_optimizer(total_loss, learning_rate,\n",
        "                                                          num_train_steps, num_warmup_steps,\n",
        "                                                          use_tpu=False)\n",
        "            \n",
        "            tvars = tf.trainable_variables()\n",
        "            initialized_variable_names = {}\n",
        "            scaffold_fn = None\n",
        "            if init_checkpoint:\n",
        "                (assignment_map, initialized_variable_names\n",
        "                ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "                \n",
        "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "                \n",
        "            tf.logging.info(\"**** Trainable Variables ****\")\n",
        "            for var in tvars:\n",
        "                init_string = ''\n",
        "                if var.name in initialized_variable_names:\n",
        "                    init_string = ', *INIT_FROM_CKPT*'\n",
        "                tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "            \n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                output_spec = tf.estimator.EstimatorSpec(\n",
        "                                mode=mode,\n",
        "                                loss=total_loss,\n",
        "                                train_op=optimizer)\n",
        "                \n",
        "            elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "                eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "                output_spec = tf.estimator.EstimatorSpec(\n",
        "                                mode=mode,\n",
        "                                loss=total_loss,\n",
        "                                eval_metric_ops=eval_metrics)\n",
        "                \n",
        "        # predicting\n",
        "        elif not is_training:\n",
        "            (predicted_labels, log_probs) = create_model(bert_config, is_training,\n",
        "                                                          input_ids, input_mask,\n",
        "                                                          segment_ids, label_ids,\n",
        "                                                          num_labels)\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                                mode=mode,\n",
        "                                predictions={\n",
        "                                    'probabilities': log_probs,\n",
        "                                    'labels': predicted_labels\n",
        "                                })\n",
        "    \n",
        "        print(output_spec)\n",
        "        return output_spec\n",
        "\n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COxmbcr92JA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "model_fn = model_fn_builder(bert_config=bert_config,\n",
        "                            num_labels=len(label_list),\n",
        "                            init_checkpoint=BERT_INIT_CHKPNT,\n",
        "                            learning_rate=LEARNING_RATE,\n",
        "                            num_train_steps=num_train_steps,\n",
        "                            num_warmup_steps=num_warmup_steps,\n",
        "                            use_tpu=False,\n",
        "                            use_one_hot_embeddings=True\n",
        "                           )\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    params={\"batch_size\": BATCH_SIZE}\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaS1SqNt2JBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWrbmqOrCRH",
        "colab_type": "text"
      },
      "source": [
        "## Train with estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbZO2EaM2JBD",
        "colab_type": "code",
        "outputId": "73b76443-f229-4a6e-86a5-1891e946fcc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Begin training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('Training took time ', datetime.now() - current_time)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin training!\n",
            "Training took time  0:00:00.022142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Z03k2kqnjT",
        "colab_type": "text"
      },
      "source": [
        "## Getting the last 50 examples in test_examples as predict_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b77YkmjL2JBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_examples = test_examples[:-50]\n",
        "predict_examples = test_examples[-50:]\n",
        "\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_examples, \n",
        "                                                                  label_list,\n",
        "                                                                  MAX_SEQ_LENGTH, \n",
        "                                                                  tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoBYZZx3qu6l",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate test_examples with trained estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dbmd5xRkml2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "09eed442-836c-4c87-80aa-923c8e667c51"
      },
      "source": [
        "test_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\n",
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden size:  768\n",
            "EstimatorSpec(mode='eval', predictions={}, loss=<tf.Tensor 'loss/Mean:0' shape=() dtype=float32>, train_op=None, eval_metric_ops={'eval_accuracy': (<tf.Tensor 'accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'accuracy/update_op:0' shape=() dtype=float32>), 'f1_score': (<tf.Tensor 'f1/Max:0' shape=() dtype=float32>, <tf.Tensor 'f1/Max_1:0' shape=() dtype=float32>), 'auc': (<tf.Tensor 'auc/value:0' shape=() dtype=float32>, <tf.Tensor 'auc/update_op:0' shape=() dtype=float32>), 'precision': (<tf.Tensor 'precision/value:0' shape=() dtype=float32>, <tf.Tensor 'precision/update_op:0' shape=() dtype=float32>), 'recall': (<tf.Tensor 'recall/value:0' shape=() dtype=float32>, <tf.Tensor 'recall/update_op:0' shape=() dtype=float32>), 'true_positives': (<tf.Tensor 'true_positives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'true_positives/AssignAdd:0' shape=() dtype=float32_ref>), 'true_negatives': (<tf.Tensor 'true_negatives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'true_negatives/AssignAdd:0' shape=() dtype=float32_ref>), 'false_positives': (<tf.Tensor 'false_positives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'false_positives/AssignAdd:0' shape=() dtype=float32_ref>), 'false_negatives': (<tf.Tensor 'false_negatives/Identity:0' shape=() dtype=float32>, <tf.Tensor 'false_negatives/AssignAdd:0' shape=() dtype=float32_ref>)}, export_outputs=None, training_chief_hooks=(), training_hooks=(), scaffold=<tensorflow.python.training.monitored_session.Scaffold object at 0x7fe9f1eba780>, evaluation_hooks=(), prediction_hooks=())\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.9914619,\n",
              " 'eval_accuracy': 0.99148417,\n",
              " 'f1_score': 0.9912695,\n",
              " 'false_negatives': 19.0,\n",
              " 'false_positives': 16.0,\n",
              " 'global_step': 4160,\n",
              " 'loss': 0.056471173,\n",
              " 'precision': 0.99201196,\n",
              " 'recall': 0.9905284,\n",
              " 'true_negatives': 2088.0,\n",
              " 'true_positives': 1987.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Z0-CaDq5Ij",
        "colab_type": "text"
      },
      "source": [
        "## Predict function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKl1YaAmNKOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(examples):\n",
        "    predict_features = bert.run_classifier.convert_examples_to_features(examples, \n",
        "                                                                    label_list,\n",
        "                                                                    MAX_SEQ_LENGTH, \n",
        "                                                                    tokenizer)\n",
        "    predict_input_fn = bert.run_classifier.input_fn_builder(features=predict_features,\n",
        "                                                    seq_length=MAX_SEQ_LENGTH,\n",
        "                                                    is_training=False,\n",
        "                                                    drop_remainder=False)\n",
        "    predicted = list(estimator.predict(predict_input_fn))\n",
        "    predictions = []\n",
        "    \n",
        "    examples = list(examples)\n",
        "    for i in range(len(examples)):\n",
        "        text = examples[i].text_a\n",
        "        real_label = 'unreliable' if predict_features[i].label_id == 1 else 'reliable'\n",
        "        predicted_label = 'unreliable' if predicted[i]['labels'] == 1 else 'reliable'\n",
        "        probs = predicted[i]['probabilities']\n",
        "        predictions.append({'text': text,'probs': probs, 'predicted': predicted_label, 'real': real_label})\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l1BMvVdeKcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dd64320f-b15c-49ae-d08f-f0f8478dcacc"
      },
      "source": [
        "predictions = predict(predict_examples)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden size:  768\n",
            "EstimatorSpec(mode='infer', predictions={'probabilities': <tf.Tensor 'loss/LogSoftmax:0' shape=(?, 2) dtype=float32>, 'labels': <tf.Tensor 'loss/Squeeze_1:0' shape=<unknown> dtype=int32>}, loss=None, train_op=None, eval_metric_ops={}, export_outputs={'serving_default': <tensorflow.python.saved_model.model_utils.export_output.PredictOutput object at 0x7fe994fe4438>}, training_chief_hooks=(), training_hooks=(), scaffold=<tensorflow.python.training.monitored_session.Scaffold object at 0x7fe994ff6da0>, evaluation_hooks=(), prediction_hooks=())\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAcMILbbfmsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3926f0c-4782-49b5-f323-224538be0933"
      },
      "source": [
        "for item in predictions:\n",
        "    print('PROBS: {}, PREDICTED: {}, REAL: {}\\n'.format(item['probs'], item['predicted'], item['real']))\n",
        "    "
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROBS: [-2.6106494e-05 -1.0553666e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1055892e+01 -1.5735503e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.0894303e+01 -1.8596476e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-2.7894584e-05 -1.0486924e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.10946045e+01 -1.51394652e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-3.4331686e-05 -1.0278375e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.5510462e-05 -1.0577895e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.5748875e-05 -1.0566983e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1079879e+01 -1.5377880e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1046756e+01 -1.5973917e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-4.0768748e-05 -1.0108087e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1072077e+01 -1.5497088e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1075552e+01 -1.5497088e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.9246411 -0.1577399], PREDICTED: unreliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1108360e+01 -1.5020258e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-2.4914430e-05 -1.0601252e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.5272049e-05 -1.0585392e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1085293e+01 -1.5377880e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.10932045e+01 -1.52586726e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1092485e+01 -1.5258673e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-6.8176386e-04 -7.2911596e+00], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.0984932e+01 -1.6927575e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1109997e+01 -1.5020258e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-3.564294e-05 -1.024162e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1044438e+01 -1.5973917e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-2.9682673e-05 -1.0423547e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.5391257e-05 -1.0581994e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.4676019e-05 -1.0608856e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1109829e+01 -1.5020258e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-3.1351552e-05 -1.0370557e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.0983545e+01 -1.6927575e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1097953e+01 -1.5139465e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1111013e+01 -1.4901050e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.0747543e+01 -2.1457441e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-3.6477377e-05 -1.0217850e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1075119e+01 -1.5497088e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.0975724e+01 -1.7165990e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-2.5272049e-05 -1.0586817e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.16222305e-04 -9.05957985e+00], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.5510462e-05 -1.0576518e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-3.0159496e-05 -1.0408340e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-3.134713e-04 -8.067804e+00], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-2.5868081e-05 -1.0562312e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.1040839e+01 -1.5973917e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1000026e+01 -1.6689160e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1028461e+01 -1.6212332e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-1.1059683e+01 -1.5735503e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-2.59872868e-05 -1.05575075e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n",
            "PROBS: [-1.0990847e+01 -1.6808368e-05], PREDICTED: unreliable, REAL: unreliable\n",
            "\n",
            "PROBS: [-2.4676019e-05 -1.0609909e+01], PREDICTED: reliable, REAL: reliable\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}